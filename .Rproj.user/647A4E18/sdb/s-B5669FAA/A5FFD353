{
    "collab_server" : "",
    "contents" : "#how to change file : set working directory (setwd) then use file.rename\nlibrary(doParallel)\nlibrary(stepPlr)\nlibrary(pROC)\nlibrary(ROCR)\nlibrary(Deducer)\nlibrary(psych)\nlibrary(ROSE)\nlibrary(caret)\nlibrary(Hmisc)\nlibrary(plyr)\nlibrary(dplyr)# for %>% \nlibrary(data.table)\nlibrary(sqldf)\nlibrary(gdata)\nlibrary(utils)\nlibrary(car)# for multicollinearity\nlibrary(xlsx)# output file to excel\nlibrary(MASS)#chi-square test of independence\noptions(scipen=999)\n#find perl path for utils package\nprl <- \"/PERL/bin/perl.exe\"\n\n\n#import the data\ntrainning_set <- read.csv(\"/trainning_set.txt\", \n                          header = TRUE, sep = \",\")\n#View(trainning_set)\n\n\n#see if any missing data\n#is.na(trainning_set)\n#sum(is.na(trainning_set))#number of missing values\n\n\n# see which columns has missing data\n#trainning_na_count <- sapply(trainning_set, function(x){\n#  sum(is.na(x))\n#})\n#trainning_na_count <- data.frame(trainning_na_count)\n\n#set data types\ntrainning_set$subtype <- factor(trainning_set$subtype,levels = 1:41,ordered = FALSE)\ntrainning_set$cust_type <- factor(trainning_set$cust_type,levels = 1:10, ordered = FALSE)\ntrainning_set$ave_age <- ordered(trainning_set$ave_age, levels = 1:6)\ntrainning_set$houses <- ordered(trainning_set$houses, levels = 1:10)\ntrainning_set$household_size <- ordered(trainning_set$household_size, levels = 1:6)\ntrainning_set$mobile_home_insurance <- factor(ifelse(trainning_set$mobile_home_insurance == 1,\"y\",\"n\"))\ntrainning_set[6:64] <- lapply(trainning_set[6:64], ordered, levels = 0:9)\ntrainning_set[65:85]<- lapply(trainning_set[65:85], ordered)\ntrainning_set$purchase_power <- factor(trainning_set$purchase_power, levels = 1:8, ordered = TRUE)\nstr(trainning_set)\n\n\n#split trainning set 70:30 ratio\nset.seed(1234)\nsplitindex <- createDataPartition(trainning_set$mobile_home_insurance, \n                                  p = 0.7, \n                                  list = FALSE)\ntrain_set <- trainning_set[splitindex,]\nvalid_set <- trainning_set[-splitindex,]\n\n#balance data set\n## before\nprint(prop.table(table(trainning_set$mobile_home_insurance))*100)\n##balance data\ntrainning_set_bal <- ovun.sample(mobile_home_insurance~., \n                                 data = train_set, \n                                 p = 0.20,\n                                 seed = 1,\n                                 method = \"both\")$data\n##after\nprint(prop.table(table(trainning_set_bal$mobile_home_insurance))*100)\n\n\n#ordial vs oridal :spearman correlation\nordial_tab <- trainning_set_bal[c(2:4,6:85)]\nordial_tab<-data.frame(lapply(ordial_tab, as.numeric))\nordial_tab_2 <- cor(ordial_tab, method = \"spearman\")\nordial_tab_3 <- findCorrelation(ordial_tab_2, \n                                cutoff = 0.9,\n                                names = TRUE, \n                                exact =TRUE, \n                                verbose = TRUE) %>%\n  print()\n\n#trainning_set_bal[,ordial_tab_3] <- list(NULL)\ntrainning_set_bal$subtype<- NULL\ntrainning_set_bal$cust_type <- NULL\n\n#valid_set[,ordial_tab_3] <- list(NULL)\nvalid_set$subtype<- NULL\nvalid_set$cust_type <- NULL\n#establish train parameters\ntrain_control <- trainControl(savePredictions = TRUE,\n                              classProbs = TRUE,\n                              summaryFunction = twoClassSummary)\n\n#create model based on different methods:\n#set time\nptm <- proc.time()\nset.seed(1045)\n#parallel\ncl <- makeCluster(detectCores())\nregisterDoParallel(cl)\nmodel <- train(data = trainning_set_bal,\n               mobile_home_insurance~.,\n               trControl = train_control,\n               method = \"nnet\",\n               tuneLength = 5,\n               preProcess = c(\"center\", \"scale\",\"pca\"),\n               allowParallel = TRUE,\n               verbose = TRUE,\n               size = 3)\nsummary(model)\nstopCluster(cl)\ntime <- proc.time() - ptm\n\n#train set performance\nprobs2 <- predict(model,newdata = trainning_set_bal, type =\"prob\")\npred2  <- factor(ifelse(probs2[,\"y\"] > 0.5,\"y\",\"n\"))\nsummary(pred2)\nmatrix1 <- confusionMatrix(data = pred2, \n                           trainning_set_bal$mobile_home_insurance,\n                           positive = levels(trainning_set_bal$mobile_home_insurance)[2]) %>% \n  print()\nrocCurve1  <- roc(response = trainning_set_bal$mobile_home_insurance,\n                  predictor = probs2[,\"y\"],\n                  levels = levels(trainning_set_bal$mobile_home_insurance))\ncurve11 <- plot(rocCurve1, print.thres = c(.5), type = \"S\",\n                print.thres.pattern = \"%.3f (Spec = %.2f, Sens = %.2f)\",\n                print.thres.cex = .8,\n                legacy.axes = TRUE)\ncurve11#AUC\n\n#valid_set performance\nprobs <- predict(model,newdata = valid_set, type =\"prob\")\npred  <- factor(ifelse(probs[,\"y\"] > 0.25,\"y\",\"n\"))\nsummary(pred)\nlevels(valid_set$mobile_home_insurance)\nmatrix <- confusionMatrix(data = pred, \n                          valid_set$mobile_home_insurance,\n                          positive = levels(valid_set$mobile_home_insurance)[2]) %>% \n  print()\n\nrocCurve  <- roc(response = valid_set$mobile_home_insurance,\n                 predictor = probs[,\"y\"],\n                 levels = levels(valid_set$mobile_home_insurance))\ncurve1 <- plot(rocCurve, print.thres = c(.25), type = \"S\",\n               print.thres.pattern = \"%.3f (Spec = %.2f, Sens = %.2f)\",\n               print.thres.cex = .8,\n               legacy.axes = TRUE)\ncurve1\n\n\n#import the test data\ntest_set <- read.csv(\"D:/Drive/Data Warehousing/GROUP ASSIGNMENT/test_set.txt\",\n                     header = TRUE, sep = \",\") \n#view the data (V in uppercase)\n#View(test_set)\n\n#see if any missing data\n#is.na(test_set)\n#sum(is.na(test_set))\ntest_set$subtype <- factor(test_set$subtype,levels = 1:41,ordered = FALSE)\ntest_set$cust_type <- factor(test_set$cust_type,levels = 1:10, ordered = FALSE)\ntest_set$ave_age <- ordered(test_set$ave_age, levels = 1:6)\ntest_set$houses <- ordered(test_set$houses, levels = 1:10)\ntest_set$household_size <- ordered(test_set$household_size, levels = 1:6)\ntest_set$mobile_home_insurance <- factor(ifelse(test_set$mobile_home_insurance == 1,\"y\",\"n\"))\n#trainning_set$mobile_home_insurance <- factor(trainning_set$mobile_home_insurance, ordered = FALSE)\ntest_set[6:64] <- lapply(test_set[6:64], ordered, levels = 0:9)\ntest_set[65:85]<- lapply(test_set[65:85], ordered)\ntest_set$purchase_power <- factor(test_set$purchase_power, levels = 1:8, ordered = TRUE)\nstr(test_set)\n#test_set[,ordial_tab_3] <- list(NULL)\ntest_set$subtype<- NULL\ntest_set$cust_type <- NULL\n\nfor ( j in c(1:83) ) {\n  i = which( !( test_set[[j]] %in% levels(trainning_set_bal[[j]] ) ) )\n  test_set[i,j] <- NA\n}\n#test set performance\ntest_fin <- predict(model,newdata = test_set, type = \"prob\")\npred_test  <- factor(ifelse(test_fin[,\"y\"] > 0.25,\"y\",\"n\"))\nsummary(pred_test)\n",
    "created" : 1465788156994.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "612914069",
    "id" : "A5FFD353",
    "lastKnownWriteTime" : 1463768822,
    "last_content_update" : 1463768822,
    "path" : "F:/R/Mobile_home_purchase/R/neural_network.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}